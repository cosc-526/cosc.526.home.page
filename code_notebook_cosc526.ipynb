{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **`.M.0.setup`**"
      ],
      "metadata": {
        "id": "V_Z6BaBrLzFr"
      },
      "id": "V_Z6BaBrLzFr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M.1.Introduction to data mining`**"
      ],
      "metadata": {
        "id": "khVZ7DoGDiBn"
      },
      "id": "khVZ7DoGDiBn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`M.1.exercise.M.1.exercise.1`**"
      ],
      "metadata": {
        "id": "X-de8q4f_q13"
      },
      "id": "X-de8q4f_q13"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR2SKZ0V4l36"
      },
      "source": [
        "\n",
        "In this notebook, we provide you with basic functions for completing the assignment. *You will need to modify existing code and write new code to find a solution*. Upload your solution to the GitHub repository we assigned to you.\n",
        "\n",
        "### Problem 1\n",
        "In this problem we will explore reading in and parsing [delimiter-separated values](https://en.wikipedia.org/wiki/Delimiter-separated_values) stored in files.  We will start with [comma-separated values](https://en.wikipedia.org/wiki/Comma-separated_values) and then move on to [tab-separated values](https://en.wikipedia.org/wiki/Tab-separated_values).\n",
        "\n",
        "#### Problem 1a: Comma-Separated Values (CSV)\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Comma-separated_values): In computing, a comma-separated values (CSV) file stores tabular data (numbers and text) in plain text. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. The use of the comma as a field separator is the source of the name for this file format.\n",
        "\n",
        "If you were to consider the CSV file as a matrix, each line would represent a row and each comma would represent a column.  In the provided CSV file, the first row consists of a header that \"names\" each column.  In this problem, ...\n",
        "\n",
        "- Count (and print) the number of rows of data (header is excluded) in the csv file\n",
        "- Count (and print) the number of columns of data in the csv file\n",
        "- Calculate (and print) the average of the values that are in the \"age\" column\n",
        "  - You can assume each age in the file is an integer, but the average should be calculated as a float"
      ],
      "id": "ZR2SKZ0V4l36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0Ci_heq4l3_",
        "outputId": "6878ac29-bab2-46f9-ae40-bcbcaaa2d5d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows of data: 8\n",
            "Number of cols: 3\n",
            "Average Age: 70.875\n"
          ]
        }
      ],
      "source": [
        "def parse_delimited_file(filename, delimiter=\",\"):\n",
        "    # Open and read in all lines of the file\n",
        "    # (I do not recommend readlines for LARGE files)\n",
        "    # `open`: ref [1]\n",
        "    # `readlines`: ref [2]\n",
        "    with open(filename, 'r', encoding='utf8') as dsvfile:\n",
        "        lines = dsvfile.readlines()\n",
        "\n",
        "    # Strip off the newline from the end of each line\n",
        "    # HINT: ref [3]\n",
        "    # Using list comprehension is the recommended pythonic way to iterate through lists\n",
        "    # HINT: ref [4]\n",
        "    lines = [line.rstrip('\\n') for line in lines]\n",
        "    \n",
        "    # Split each line based on the delimiter (which, in this case, is the comma)\n",
        "    # HINT: ref [5]\n",
        "    split_lines = [line.split(delimiter) for line in lines]\n",
        "    \n",
        "    # Separate the header from the data\n",
        "    # HINT: ref [6]\n",
        "    header = split_lines[0]\n",
        "    data_lines = split_lines[1:]\n",
        "    \n",
        "    # Find \"age\" within the header\n",
        "    # (i.e., calculating the column index for \"age\")\n",
        "    # HINT: ref [7]\n",
        "    age_index = header.index(\"age\")\n",
        "\n",
        "    # Calculate the number of data rows and columns\n",
        "    # HINT: [8]\n",
        "    num_data_rows = len(data_lines)\n",
        "    num_data_cols = len(header)\n",
        "    \n",
        "    # Sum the \"age\" values\n",
        "    # HINT: ref [9]\n",
        "    sum_age = 0\n",
        "    for row in data_lines:\n",
        "        sum_age += int(row[age_index])\n",
        "        \n",
        "    # Calculate the average age\n",
        "    avg_age = sum_age / num_data_rows\n",
        "    \n",
        "    # Print the results\n",
        "    # `format`: ref [10]\n",
        "    print(\"Number of rows of data: {}\".format(num_data_rows))\n",
        "    print(\"Number of cols: {}\".format(num_data_cols))\n",
        "    print(\"Average Age: {}\".format(avg_age))\n",
        "    \n",
        "# Parse the provided csv file\n",
        "parse_delimited_file('data.csv')"
      ],
      "id": "q0Ci_heq4l3_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFtuKBBh4l4C"
      },
      "source": [
        "**Expected Ouput:**\n",
        "```\n",
        "Number of rows of data: 8\n",
        "Number of cols: 3\n",
        "Average Age: 70.875\n",
        "```\n",
        "**References:**\n",
        "- [1: open](https://docs.python.org/3.6/library/functions.html#open)\n",
        "- [2: readlines](https://docs.python.org/3.6/library/codecs.html#codecs.StreamReader.readlines)\n",
        "- [3: rstrip](https://docs.python.org/3.6/library/stdtypes.html#str.rstrip)\n",
        "- [4: list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)\n",
        "- [5: split](https://docs.python.org/3.6/library/stdtypes.html#str.split)\n",
        "- [6: splice](https://docs.python.org/3.6/glossary.html#term-slice)\n",
        "- [7: \"more on lists\"](https://docs.python.org/3.6/tutorial/datastructures.html#more-on-lists)\n",
        "- [8: len](https://docs.python.org/3.6/library/functions.html#len)\n",
        "- [9: int](https://docs.python.org/3.6/library/functions.html#int)\n",
        "- [10: format](https://docs.python.org/3.6/library/stdtypes.html#str.format)\n"
      ],
      "id": "fFtuKBBh4l4C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybWXMZ974l4D"
      },
      "source": [
        "### Problem 1b: Tab-Separated Values (TSV)\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Tab-separated_values): A tab-separated values (TSV) file is a simple text format for storing data in a tabular structure, e.g., database table or spreadsheet data, and a way of exchanging information between databases. Each record in the table is one line of the text file. Each field value of a record is separated from the next by a tab character. The TSV format is thus a type of the more general delimiter-separated values format.\n",
        "\n",
        "In this problem, repeat the analyses performed in the prevous problem, but for the provided tab-delimited file.\n",
        "\n",
        "**NOTE:** the order of the columns has changed in this file.  If you hardcoded the position of the \"age\" column, think about how you can generalize the `parse_delimited_file` function to work for any delimited file with an \"age\" column."
      ],
      "id": "ybWXMZ974l4D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZrO7SLg4l4D",
        "outputId": "7eb7cfed-e49b-4e28-bec0-40ae22298599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows of data: 8\n",
            "Number of cols: 3\n",
            "Average Age: 70.875\n"
          ]
        }
      ],
      "source": [
        "# Further reading on optional arguments, like \"delimiter\": http://www.diveintopython.net/power_of_introspection/optional_arguments.html\n",
        "parse_delimited_file('data.tsv', delimiter=\"\\t\")"
      ],
      "id": "-ZrO7SLg4l4D"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSr6LhyN4l4E"
      },
      "source": [
        "**Expected Ouput:**\n",
        "```\n",
        "Number of rows of data: 8\n",
        "Number of cols: 3\n",
        "Average Age: 70.875\n",
        "```\n",
        "---\n",
        "\n",
        "### Problem 2\n",
        "If you opened the `data.csv` file, you may have noticed some non-english letters in the names column.  These characters are represented using [Unicode](https://en.wikipedia.org/wiki/Unicode), a standard for representing many different types and forms of text.  Python 3 [natively supports](https://docs.python.org/3/howto/unicode.html) Unicode, but many tools do not.  Some tools require text to be formatted with [ASCII](https://en.wikipedia.org/wiki/ASCII).\n",
        "\n",
        "Convert the unicode-formatted names into ascii-formated names, and save the names out to a file named `data-ascii.txt` (one name per line).  We have provided you with a [tranliteration dictionary](https://german.stackexchange.com/questions/4992/conversion-table-for-diacritics-e-g-%C3%BC-%E2%86%92-ue) that maps several common unicode characters to their ascii transliteration.  Use this dictionary to convert the unicode strings to ascii."
      ],
      "id": "LSr6LhyN4l4E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17tX_qpT4l4F",
        "outputId": "dc9c4f18-603f-4b45-9cd8-c0e1f4608a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Richard Phillips Feynman\n",
            "Shin'ichiro Tomonaga\n",
            "Julian Schwinger\n",
            "Rudolf Ludwig Moessbauer\n",
            "Erwin Schroedinger\n",
            "Paul Dirac\n",
            "Maria Sklodowska-Curie\n",
            "Pierre Curie\n"
          ]
        }
      ],
      "source": [
        "translit_dict = {\n",
        "    \"ä\" : \"ae\",\n",
        "    \"ö\" : \"oe\",\n",
        "    \"ü\" : \"ue\",\n",
        "    \"Ä\" : \"Ae\",\n",
        "    \"Ö\" : \"Oe\",\n",
        "    \"Ü\" : \"Ue\", \n",
        "    \"ł\" : \"l\",\n",
        "    \"ō\" : \"o\",\n",
        "}\n",
        "\n",
        "with open(\"data.csv\", 'r', encoding='utf8') as csvfile:\n",
        "    lines = csvfile.readlines()\n",
        "\n",
        "# Strip off the newline from the end of each line\n",
        "lines = [line.rstrip() for line in lines]\n",
        "    \n",
        "# Split each line based on the delimiter (which, in this case, is the comma)\n",
        "split_lines = [line.split(\",\") for line in lines]\n",
        "\n",
        "# Separate the header from the data\n",
        "header = split_lines[0]\n",
        "data_lines = split_lines[1:]\n",
        "    \n",
        "# Find \"name\" within the header\n",
        "name_index = header.index(\"name\")\n",
        "\n",
        "# Extract the names from the rows\n",
        "unicode_names = [line[name_index] for line in data_lines]\n",
        "\n",
        "# Iterate over the names\n",
        "translit_names = []\n",
        "for unicode_name in unicode_names:\n",
        "    # Perform the replacements in the translit_dict\n",
        "    # HINT: ref [1]\n",
        "    translit_name = unicode_name\n",
        "    for key, value in translit_dict.items():\n",
        "        translit_name = translit_name.replace(key, value)\n",
        "    translit_names.append(translit_name)\n",
        "\n",
        "# Write out the names to a file named \"data-ascii.txt\"\n",
        "# HINT: ref [2]\n",
        "with open(\"data-ascii.txt\", 'w') as outfile:\n",
        "    for name in translit_names:\n",
        "        outfile.write(name + \"\\n\")\n",
        "\n",
        "# Verify that the names were converted and written out correctly\n",
        "with open(\"data-ascii.txt\", 'r') as infile:\n",
        "    for line in infile:\n",
        "        print(line.rstrip())"
      ],
      "id": "17tX_qpT4l4F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmOzzRTl4l4P"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Richard Phillips Feynman\n",
        "Shin'ichiro Tomonaga\n",
        "Julian Schwinger\n",
        "Rudolf Ludwig Moessbauer\n",
        "Erwin Schroedinger\n",
        "Paul Dirac\n",
        "Maria Sklodowska-Curie\n",
        "Pierre Curie\n",
        "```\n",
        "\n",
        "**References:**\n",
        "- [1: replace](https://docs.python.org/3.6/library/stdtypes.html#str.replace)\n",
        "- [2: file object methods](https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects)"
      ],
      "id": "zmOzzRTl4l4P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIuY9ADb4l4P"
      },
      "source": [
        "### Practical Tasks:\n",
        "\n",
        "This set of practical tasks is **due on Jan 17, 2020 (before 8:00AM ET).**\n",
        "\n",
        "**Definitions:**\n",
        "- **GitHub:** web-based hosting service for version control used to distribute and collect assignments as well as other class materials (e.g., slides, code, and datasets)\n",
        "- **Git:** software used by GitHub\n",
        "\n",
        "**Practcal Tasks:** \n",
        "- Create your own GitHub account\n",
        "- Submit your GitHub username to the Google form: https://forms.gle/CKugke8Dzqjm9tQ89\n",
        "- Install Git on your laptop"
      ],
      "id": "VIuY9ADb4l4P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcOqXMMu4l4Q"
      },
      "source": [
        "### Free-Form Questions:\n",
        "\n",
        "The answers to the following questions are **due on Jan 17, 2020 (before 3:35PM ET)."
      ],
      "id": "RcOqXMMu4l4Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBxeGIAw4l4Q"
      },
      "source": [
        "Your solutions for Problems 1 & 2 probably share a lot of code in common. You might even have copied-and-pasted from Problem 1 into Problem 2. Refactor parse_delimited_file to be useful in both problems"
      ],
      "id": "IBxeGIAw4l4Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyaqsgXN4l4Q"
      },
      "outputs": [],
      "source": [
        "# Add here your code "
      ],
      "id": "YyaqsgXN4l4Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcx8OGuC4l4R"
      },
      "source": [
        "Are there any pre-built Python packages that could help you solve these problems? If yes, refactor your solutions to use those packages.  "
      ],
      "id": "Mcx8OGuC4l4R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3Ll4w6b4l4R"
      },
      "outputs": [],
      "source": [
        "# Add here your code "
      ],
      "id": "c3Ll4w6b4l4R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYQTYr9Q4l4R"
      },
      "source": [
        "Tell us about your experience (for each quesiton provide a couple of sentences).\n",
        "- Describe the challenges you faced in addressing these tasks and how you overcame these challenges.\n",
        "- Did you work with other students on this assignment? If yes, how did you help them? How did they help you? "
      ],
      "id": "DYQTYr9Q4l4R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoTx4tRc4l4S"
      },
      "source": [
        "*Write here your answers*"
      ],
      "id": "UoTx4tRc4l4S"
    },
    {
      "cell_type": "markdown",
      "id": "5f09fcd7",
      "metadata": {
        "id": "5f09fcd7"
      },
      "source": [
        "## **`M.1.assign.M.1.assignment` - Data Mining with Covid Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Import and manipulate a .csv file  \n",
        "2.   Assess your Python Programming Skills  \n",
        "\n",
        "*  Other assignments are more challenging. Use this one to assess your skills.\n",
        "*  Attempt to solve the problems without searching for online assistance.\n",
        "*  Prepare resource questions for the class discussion to help source additional tools."
      ],
      "metadata": {
        "id": "nxkO9IDmZsmK"
      },
      "id": "nxkO9IDmZsmK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`Task.0`** Import, inspect, and view descriptive statistics   \n"
      ],
      "metadata": {
        "id": "RNiLo5Rm9SM2"
      },
      "id": "RNiLo5Rm9SM2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import data and view descriptive statistics with the pandas library.  \n",
        "\n"
      ],
      "metadata": {
        "id": "25Y8fRk8Zfcd"
      },
      "id": "25Y8fRk8Zfcd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Kaggle](https://www.kaggle.com/yamqwe/omicron-covid19-variant-daily-cases?select=covid-variants.csv) home, use your kaggle API (or get one if you like), URL via class GitHub, or the .csv file.    \n",
        "* Dataset contains information about the processing of COVID-19 sequences by different countries over time.  \n",
        "* The data fields or columns are  \n",
        "1. `location`: the country for which the information is provided  \n",
        "2. `date`: the date of the data entry  \n",
        "3. `variant`: the COVID-19 variant for the data entry  \n",
        "4. `num_sequences`: the number of sequences **processed** (for the country, variant, and date)  \n",
        "5. `num_sequences_total`: the number of sequences **available** (for the country, variant, and date)  \n",
        "6. `perc_sequences`: the percentage of available number of sequences that were processed (*Note: this value is out of 100*)  \n",
        "`note:` each dataset row represents the processing of *one* variant by *one* country on *one* day.  \n"
      ],
      "metadata": {
        "id": "L9116iIaLZS8"
      },
      "id": "L9116iIaLZS8"
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter solution here\n"
      ],
      "metadata": {
        "id": "J6JeWBO2Cw78"
      },
      "id": "J6JeWBO2Cw78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ba54e2",
      "metadata": {
        "id": "c0ba54e2"
      },
      "outputs": [],
      "source": [
        "#in notebook and colab use !pip freeze to check for specific library\n",
        "#!pip freeze | grep <library_name> command, where <library_name>\n",
        "!pip freeze | grep pandas\n",
        "!pip freeze | grep numpy\n",
        "!pip freeze | grep matplotlib\n",
        "\n",
        "#use the following if \n",
        "#!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#=> Read Data\n",
        "#=> from a url into pandas or once loaded in notebook\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/cosc-526/cosc.526.home.page/main/d.M.1.10.assignment.covid.data.variants.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "8XCKzy-Pfbuw"
      },
      "id": "8XCKzy-Pfbuw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optional, kaggle direct; need an account and an API!\n",
        "\n",
        "#!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/   #need to use your kaggle api key\n",
        "'chmod 600 /root/.kaggle/kaggle.json'\n",
        "kaggle.api.authenticate()\n",
        "print(\"done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDR43QX93Kb3",
        "outputId": "eda98d7f-c93b-487f-c923-2cfadc945637"
      },
      "id": "RDR43QX93Kb3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==>api validated<==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`Task.0 - Expected Outcome`**  "
      ],
      "metadata": {
        "id": "4z6COkzkC2KU"
      },
      "id": "4z6COkzkC2KU"
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "import pandas as pd\n",
        "\n",
        "!kaggle datasets download -d gpreda/covid19-variants\n",
        "\n",
        "# Load data into a pandas DataFrame\n",
        "df = pd.read_csv('covid19-variants.zip')\n",
        "\n",
        "# display a view of the imported data, function = pd.head()\n",
        "print(\"------------------------------\")\n",
        "print(\"> dataframe fields w pd.head <\")\n",
        "print(\"------------------------------\")\n",
        "print(df.head())\n",
        "\n",
        "# display descriptive statistics\n",
        "print(\"------------------------------\")\n",
        "print(\"==> descriptive statistics <==\")\n",
        "print(\"------------------------------\")\n",
        "print(round(df.describe()),1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9ouy2J0z92o",
        "outputId": "23bc689d-a129-4fe0-fa79-bab7ba489ec3"
      },
      "id": "S9ouy2J0z92o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "covid19-variants.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "------------------------------\n",
            "> dataframe fields w pd.head <\n",
            "------------------------------\n",
            "  location        date    variant  num_sequences  perc_sequences  \\\n",
            "0   Angola  2020-07-06      Alpha              0             0.0   \n",
            "1   Angola  2020-07-06  B.1.1.277              0             0.0   \n",
            "2   Angola  2020-07-06  B.1.1.302              0             0.0   \n",
            "3   Angola  2020-07-06  B.1.1.519              0             0.0   \n",
            "4   Angola  2020-07-06    B.1.160              0             0.0   \n",
            "\n",
            "   num_sequences_total  \n",
            "0                    3  \n",
            "1                    3  \n",
            "2                    3  \n",
            "3                    3  \n",
            "4                    3  \n",
            "------------------------------\n",
            "==> descriptive statistics <==\n",
            "------------------------------\n",
            "       num_sequences  perc_sequences  num_sequences_total\n",
            "count       100416.0        100416.0             100416.0\n",
            "mean            72.0             6.0               1510.0\n",
            "std           1669.0            22.0               8445.0\n",
            "min              0.0            -0.0                  1.0\n",
            "25%              0.0             0.0                 12.0\n",
            "50%              0.0             0.0                 59.0\n",
            "75%              0.0             0.0                394.0\n",
            "max         142280.0           100.0             146170.0 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760c5a8f",
      "metadata": {
        "id": "760c5a8f"
      },
      "source": [
        "### **`Task.1`** - find uncommon variants  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 3 main variants of COVID-19 that we've experienced in the US are:  \n",
        "\n",
        "*  `Alpha`  \n",
        "*  `Delta`  \n",
        "*  `Omicron`  \n",
        "\n",
        "**Assignment Tasks**\n",
        "1. What other variants are recognized by the World Health Organization (WHO) in this dataset?  \n",
        "\n",
        "2. Sort the variant names alphanumerically and store in a list.  \n",
        "\n",
        "3. exclude in output `on_who` and `others` from `variant`.  "
      ],
      "metadata": {
        "id": "ZGy_VBO4DDyd"
      },
      "id": "ZGy_VBO4DDyd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter solution here"
      ],
      "metadata": {
        "id": "vxMduRg5Cj5u"
      },
      "id": "vxMduRg5Cj5u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`Task.1 Solution`**  \n",
        "*  pandas function df.select_dtypes() gets a list of column names but excludes data types we don't need; int64, float64\n",
        "\n",
        "* **`didn't think to use data types?`** here they are: \n",
        "https://pandas.pydata.org/docs/reference/arrays.html\n",
        "\n",
        "* Use for loop to iterate through each non-numeric column name and call pd.crosstab() to create a frequency distribution for each column.\n",
        "\n",
        "* Note that pd.crosstab() can also take multiple column names as arguments, allowing you to create cross-tabulations for multiple categorical variables at once"
      ],
      "metadata": {
        "id": "KQKF_R5Ufrid"
      },
      "id": "KQKF_R5Ufrid"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list of columns without integer or decimal numbers\n",
        "mylist_No_Numbers = df.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "#remove the date variable for a cleaner view\n",
        "mylist_No_Numbers.remove('date')\n",
        "print(\"list category names are: \",mylist_No_Numbers)\n",
        "print(\"------------------------------------------\")\n",
        "# Loop through each non-numeric column and display a crosstab of data\n",
        "print(\"My summary of all categories \")\n",
        "for col in mylist_No_Numbers:\n",
        "    print(pd.crosstab(index=df[col], columns='count'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv4_m-XQfcOR",
        "outputId": "38267f85-d70a-4f36-9008-36d2f064950f"
      },
      "id": "Jv4_m-XQfcOR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list category names are:  ['location', 'variant']\n",
            "------------------------------------------\n",
            "My summary of all categories \n",
            "col_0          count\n",
            "location            \n",
            "Angola           672\n",
            "Argentina       1056\n",
            "Aruba            600\n",
            "Australia       1056\n",
            "Austria         1032\n",
            "...              ...\n",
            "United States   1080\n",
            "Uruguay          576\n",
            "Vietnam          504\n",
            "Zambia           816\n",
            "Zimbabwe         672\n",
            "\n",
            "[121 rows x 1 columns]\n",
            "col_0           count\n",
            "variant              \n",
            "Alpha            4184\n",
            "B.1.1.277        4184\n",
            "B.1.1.302        4184\n",
            "B.1.1.519        4184\n",
            "B.1.160          4184\n",
            "B.1.177          4184\n",
            "B.1.221          4184\n",
            "B.1.258          4184\n",
            "B.1.367          4184\n",
            "B.1.620          4184\n",
            "Beta             4184\n",
            "Delta            4184\n",
            "Epsilon          4184\n",
            "Eta              4184\n",
            "Gamma            4184\n",
            "Iota             4184\n",
            "Kappa            4184\n",
            "Lambda           4184\n",
            "Mu               4184\n",
            "Omicron          4184\n",
            "S:677H.Robin1    4184\n",
            "S:677P.Pelican   4184\n",
            "non_who          4184\n",
            "others           4184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out catch all categories\n",
        "unwanted_categories = ['non_who','others']\n",
        "mylist_filtered = [category for category in df['variant'] if category not in unwanted_categories]\n",
        "mylist_filtered.sort()\n",
        "print(pd.crosstab(index=mylist_filtered, columns='count'))\n",
        "print(\"total.categories=\",len(pd.crosstab(index=mylist_filtered,columns='count')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vnPwy2EkCuQ",
        "outputId": "b3d15797-f8e1-4a24-d592-99a51dd030e6"
      },
      "id": "7vnPwy2EkCuQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "col_0           count\n",
            "row_0                \n",
            "Alpha            4184\n",
            "B.1.1.277        4184\n",
            "B.1.1.302        4184\n",
            "B.1.1.519        4184\n",
            "B.1.160          4184\n",
            "B.1.177          4184\n",
            "B.1.221          4184\n",
            "B.1.258          4184\n",
            "B.1.367          4184\n",
            "B.1.620          4184\n",
            "Beta             4184\n",
            "Delta            4184\n",
            "Epsilon          4184\n",
            "Eta              4184\n",
            "Gamma            4184\n",
            "Iota             4184\n",
            "Kappa            4184\n",
            "Lambda           4184\n",
            "Mu               4184\n",
            "Omicron          4184\n",
            "S:677H.Robin1    4184\n",
            "S:677P.Pelican   4184\n",
            "total.categories= 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4f869b7",
      "metadata": {
        "id": "c4f869b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b42597-b64d-4b1a-e181-8bd7c3032b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       num_sequences  perc_sequences  num_sequences_total\n",
            "count       100416.0        100416.0             100416.0\n",
            "mean            72.0             6.0               1510.0\n",
            "std           1669.0            22.0               8445.0\n",
            "min              0.0            -0.0                  1.0\n",
            "25%              0.0             0.0                 12.0\n",
            "50%              0.0             0.0                 59.0\n",
            "75%              0.0             0.0                394.0\n",
            "max         142280.0           100.0             146170.0 1\n",
            "   variant  count\n",
            "0    Alpha   4184\n",
            "1     Beta   4184\n",
            "2    Delta   4184\n",
            "3    Gamma   4184\n",
            "4   Lambda   4184\n",
            "5  Omicron   4184\n"
          ]
        }
      ],
      "source": [
        "print(round(df.describe()),1)\n",
        "# Filter out the \"others\" and \"non_who\" variant categories\n",
        "df = df[df.variant.isin(['Alpha', 'Beta', 'Delta', 'Gamma', 'Lambda', 'Omicron'])]\n",
        "\n",
        "# Group the data by the \"variant\" variable and count the occurrences\n",
        "variant_counts = df.groupby('variant').size().reset_index(name='count')\n",
        "\n",
        "# Print the resulting table\n",
        "print(variant_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cbdeb65",
      "metadata": {
        "id": "5cbdeb65"
      },
      "source": [
        "1.8.2. Find the Most Processed Variant\n",
        "\n",
        "Determine which variant of COVID-19 has the most sequences processed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9efb902",
      "metadata": {
        "id": "e9efb902"
      },
      "outputs": [],
      "source": [
        "## Write here your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663db8ac",
      "metadata": {
        "id": "663db8ac"
      },
      "source": [
        "### **`Task.3`** Which country best at sequence processing?\n",
        "\n",
        "Which country processed sequences the best of all variants including the “catch-all” categories?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c31b41",
      "metadata": {
        "id": "75c31b41"
      },
      "outputs": [],
      "source": [
        "## Write here your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`Task. - Expected Outcome`**  "
      ],
      "metadata": {
        "id": "A-Luk0KveLoq"
      },
      "id": "A-Luk0KveLoq"
    },
    {
      "cell_type": "markdown",
      "id": "11d1d3a0",
      "metadata": {
        "id": "11d1d3a0"
      },
      "source": [
        "### 1.8.4a. Find Best Country at Processing Specific Sequences\n",
        "\n",
        "Determine which country did the best at processing sequences across the Alpha, Delta, and Omicron variants.\n",
        "\n",
        "The output should be the name of a single country.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcafdd2e",
      "metadata": {
        "id": "fcafdd2e"
      },
      "outputs": [],
      "source": [
        "## Write here your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`Task. - Expected Outcome`**  "
      ],
      "metadata": {
        "id": "fvANdWH2kOqc"
      },
      "id": "fvANdWH2kOqc"
    },
    {
      "cell_type": "markdown",
      "id": "9ccb8782",
      "metadata": {
        "id": "9ccb8782"
      },
      "source": [
        "### 1.8.4b. Find the Ranking of the US at Processing Specific Sequences\n",
        "\n",
        "Determine the ranking of the US at processing sequences across the Alpha, Delta, and Omicron variants.\n",
        "\n",
        "Store the ranking as an integer.\n",
        "\n",
        "*Note: the best country has a ranking of 1, but indexing in Python starts at 0.*\n",
        "\n",
        "*Note: in Jupyter, variables from already executed code cells are available in other code cells. This means you shouldn't have to copy and paste code from problem 4a.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "038e81b5",
      "metadata": {
        "id": "038e81b5"
      },
      "outputs": [],
      "source": [
        "## Write here your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`Task. - Expected Outcome`**  "
      ],
      "metadata": {
        "id": "G5SUmnTckQBM"
      },
      "id": "G5SUmnTckQBM"
    },
    {
      "cell_type": "markdown",
      "id": "283e46d3",
      "metadata": {
        "id": "283e46d3"
      },
      "source": [
        "### 1.8.5. Find the Number of Processed Sequences Per Country on Date\n",
        "\n",
        "Determine each country's total number of processed sequences for the Omicron variant on December 27, 2021.\n",
        "\n",
        "Sort the output from the highest number of processed sequences to the smallest number of processed sequences.\n",
        "\n",
        "Store the result as a list of tuples, with each tuple containing the country name first and the number of processed sequences second.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf6efa9",
      "metadata": {
        "id": "6cf6efa9"
      },
      "outputs": [],
      "source": [
        "## Write here your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`Task. - Expected Outcome`**  "
      ],
      "metadata": {
        "id": "vWSim_rykQeP"
      },
      "id": "vWSim_rykQeP"
    },
    {
      "cell_type": "markdown",
      "id": "c2e3afa3",
      "metadata": {
        "id": "c2e3afa3"
      },
      "source": [
        "### 1.8.6. Find Percentage of Sequences Processed in the US\n",
        "\n",
        "Determine the percentage of processed sequences for the Alpha, Delta, and Omicron variants in the US.\n",
        "\n",
        "Store the result as a dictionary where keys are variant names and values are percentages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53126a9c",
      "metadata": {
        "id": "53126a9c"
      },
      "outputs": [],
      "source": [
        "## Write here your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`Task. - Expected Outcome`**  "
      ],
      "metadata": {
        "id": "bIm0KN6TkUv8"
      },
      "id": "bIm0KN6TkUv8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`Task. - Expected Outcome`**  "
      ],
      "metadata": {
        "id": "BTlc_i5SkVDl"
      },
      "id": "BTlc_i5SkVDl"
    },
    {
      "cell_type": "markdown",
      "id": "07cc884c",
      "metadata": {
        "id": "07cc884c"
      },
      "source": [
        "### 1.8.7. Report any assignment challenges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b3be80e",
      "metadata": {
        "id": "7b3be80e"
      },
      "outputs": [],
      "source": [
        "# Write here your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M2 - Data preprocessing`**"
      ],
      "metadata": {
        "id": "Hn4Iuwq2L36e"
      },
      "id": "Hn4Iuwq2L36e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M3 - Algorithms: Unsupervised`**"
      ],
      "metadata": {
        "id": "a4PeBkYJ6L95"
      },
      "id": "a4PeBkYJ6L95"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M4 - Algorithms: Supervised`**"
      ],
      "metadata": {
        "id": "ogwwvpsJ6MGI"
      },
      "id": "ogwwvpsJ6MGI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M5 - Part I of II: Apache Spark`**"
      ],
      "metadata": {
        "id": "LE3iVztj6MLp"
      },
      "id": "LE3iVztj6MLp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M6 - Part II of II: Apache Spark`**"
      ],
      "metadata": {
        "id": "zuvgtcMS6MSB"
      },
      "id": "zuvgtcMS6MSB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M7 - Review final project success requirements`**"
      ],
      "metadata": {
        "id": "m_o-TAG56MWo"
      },
      "id": "m_o-TAG56MWo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M8 - Data science interviewing`**"
      ],
      "metadata": {
        "id": "rG70DXQn6MZ8"
      },
      "id": "rG70DXQn6MZ8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`M9 - Recommender Systems`**"
      ],
      "metadata": {
        "id": "iBNcMUha6MdA"
      },
      "id": "iBNcMUha6MdA"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "X-de8q4f_q13",
        "ZR2SKZ0V4l36",
        "ybWXMZ974l4D",
        "LSr6LhyN4l4E",
        "RcOqXMMu4l4Q",
        "RNiLo5Rm9SM2",
        "25Y8fRk8Zfcd",
        "4z6COkzkC2KU",
        "760c5a8f",
        "KQKF_R5Ufrid"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}